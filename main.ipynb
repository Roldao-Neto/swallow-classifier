{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "mp3s = []\n",
    "with open('class.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        mp3s.append(row[3])\n",
    "\n",
    "print(mp3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.4528242e-06 -9.2906685e-06  2.0058928e-06 ... -4.9318102e-01\n",
      " -5.0933820e-01 -2.8733018e-01] 22050\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('MP3/a00001.mp3')\n",
    "\n",
    "print(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [02:36<00:00,  3.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a00001.mp3</td>\n",
       "      <td>0.619257</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.588934</td>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.569039</td>\n",
       "      <td>0.558396</td>\n",
       "      <td>0.591615</td>\n",
       "      <td>0.588218</td>\n",
       "      <td>0.560607</td>\n",
       "      <td>...</td>\n",
       "      <td>4.281882e-10</td>\n",
       "      <td>1.909807e-10</td>\n",
       "      <td>7.390955e-11</td>\n",
       "      <td>2.327350e-11</td>\n",
       "      <td>5.271166e-12</td>\n",
       "      <td>6.337472e-13</td>\n",
       "      <td>2.011956e-18</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>2156.591789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a00002.mp3</td>\n",
       "      <td>0.579076</td>\n",
       "      <td>0.561442</td>\n",
       "      <td>0.574778</td>\n",
       "      <td>0.592735</td>\n",
       "      <td>0.597341</td>\n",
       "      <td>0.586346</td>\n",
       "      <td>0.579085</td>\n",
       "      <td>0.572200</td>\n",
       "      <td>0.559282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.139711e-09</td>\n",
       "      <td>1.539082e-09</td>\n",
       "      <td>8.650396e-10</td>\n",
       "      <td>2.426455e-10</td>\n",
       "      <td>5.128043e-11</td>\n",
       "      <td>5.746652e-12</td>\n",
       "      <td>-3.844897e-18</td>\n",
       "      <td>0.028103</td>\n",
       "      <td>2397.148754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a00003.mp3</td>\n",
       "      <td>0.659991</td>\n",
       "      <td>0.666785</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.595084</td>\n",
       "      <td>0.606930</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>0.548508</td>\n",
       "      <td>0.509913</td>\n",
       "      <td>...</td>\n",
       "      <td>6.524517e-10</td>\n",
       "      <td>2.924378e-10</td>\n",
       "      <td>1.136979e-10</td>\n",
       "      <td>3.595582e-11</td>\n",
       "      <td>8.174939e-12</td>\n",
       "      <td>9.862338e-13</td>\n",
       "      <td>-3.123518e-18</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>2459.667285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a00004.mp3</td>\n",
       "      <td>0.595119</td>\n",
       "      <td>0.439680</td>\n",
       "      <td>0.370019</td>\n",
       "      <td>0.396822</td>\n",
       "      <td>0.355503</td>\n",
       "      <td>0.330981</td>\n",
       "      <td>0.379730</td>\n",
       "      <td>0.433511</td>\n",
       "      <td>0.469010</td>\n",
       "      <td>...</td>\n",
       "      <td>6.382352e-09</td>\n",
       "      <td>2.917218e-09</td>\n",
       "      <td>1.173286e-09</td>\n",
       "      <td>3.822386e-10</td>\n",
       "      <td>8.864106e-11</td>\n",
       "      <td>1.096800e-11</td>\n",
       "      <td>-1.066811e-17</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>2727.688972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a00005.mp3</td>\n",
       "      <td>0.600767</td>\n",
       "      <td>0.576361</td>\n",
       "      <td>0.621725</td>\n",
       "      <td>0.593066</td>\n",
       "      <td>0.625016</td>\n",
       "      <td>0.594525</td>\n",
       "      <td>0.563292</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.565713</td>\n",
       "      <td>...</td>\n",
       "      <td>7.882182e-09</td>\n",
       "      <td>3.650343e-09</td>\n",
       "      <td>1.447736e-09</td>\n",
       "      <td>4.803207e-10</td>\n",
       "      <td>1.184225e-10</td>\n",
       "      <td>1.468444e-11</td>\n",
       "      <td>-3.253190e-18</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>2234.135857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0  a00001.mp3  0.619257  0.591173  0.588934  0.576050  0.569039  0.558396   \n",
       "1  a00002.mp3  0.579076  0.561442  0.574778  0.592735  0.597341  0.586346   \n",
       "2  a00003.mp3  0.659991  0.666785  0.614245  0.595386  0.595084  0.606930   \n",
       "3  a00004.mp3  0.595119  0.439680  0.370019  0.396822  0.355503  0.330981   \n",
       "4  a00005.mp3  0.600767  0.576361  0.621725  0.593066  0.625016  0.594525   \n",
       "\n",
       "        7         8         9    ...           428           429  \\\n",
       "0  0.591615  0.588218  0.560607  ...  4.281882e-10  1.909807e-10   \n",
       "1  0.579085  0.572200  0.559282  ...  4.139711e-09  1.539082e-09   \n",
       "2  0.569941  0.548508  0.509913  ...  6.524517e-10  2.924378e-10   \n",
       "3  0.379730  0.433511  0.469010  ...  6.382352e-09  2.917218e-09   \n",
       "4  0.563292  0.547832  0.565713  ...  7.882182e-09  3.650343e-09   \n",
       "\n",
       "            430           431           432           433           434  \\\n",
       "0  7.390955e-11  2.327350e-11  5.271166e-12  6.337472e-13  2.011956e-18   \n",
       "1  8.650396e-10  2.426455e-10  5.128043e-11  5.746652e-12 -3.844897e-18   \n",
       "2  1.136979e-10  3.595582e-11  8.174939e-12  9.862338e-13 -3.123518e-18   \n",
       "3  1.173286e-09  3.822386e-10  8.864106e-11  1.096800e-11 -1.066811e-17   \n",
       "4  1.447736e-09  4.803207e-10  1.184225e-10  1.468444e-11 -3.253190e-18   \n",
       "\n",
       "        435          436  437  \n",
       "0  0.011107  2156.591789    0  \n",
       "1  0.028103  2397.148754    1  \n",
       "2  0.019389  2459.667285    0  \n",
       "3  0.013760  2727.688972    0  \n",
       "4  0.010872  2234.135857    0  \n",
       "\n",
       "[5 rows x 438 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = []\n",
    "i = 0\n",
    "for mp3 in tqdm(glob.glob('MP3/*.mp3')):\n",
    "    nome = os.path.basename(mp3)\n",
    "    y, sr = librosa.load(mp3)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    rhythm_features = librosa.feature.tempogram(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    #centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    #flux = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    #harmonics = librosa.effects.harmonic(y=y)\n",
    "    #mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    \n",
    "    chroma_stft = np.mean(chroma_stft,axis=1)\n",
    "    rmse = np.mean(rmse,axis=1)\n",
    "    spec_cent = np.mean(spec_cent,axis=1)\n",
    "    spec_bw = np.mean(spec_bw,axis=1)\n",
    "    rolloff = np.mean(rolloff,axis=1)\n",
    "    zcr = np.mean(zcr,axis=1)\n",
    "    mfcc = np.mean(mfcc,axis=1)\n",
    "    contrast = np.mean(contrast, axis=1)\n",
    "    tonnetz = np.mean(tonnetz, axis=1)\n",
    "    rhythm_features = np.mean(rhythm_features, axis=1)\n",
    "    flatness = np.mean(flatness, axis=1)\n",
    "    bandwidth = np.mean(bandwidth, axis=1)\n",
    "    #centroid = np.mean(centroid, axis=1)\n",
    "    #mel_spectrogram = np.mean(mel_spectrogram, axis=1)\n",
    "\n",
    "    atributos = [nome]\n",
    "    atributos.extend(chroma_stft)\n",
    "    atributos.extend(rmse)\n",
    "    atributos.extend(spec_cent)\n",
    "    atributos.extend(spec_bw)\n",
    "    atributos.extend(rolloff)\n",
    "    atributos.extend(zcr)\n",
    "    atributos.extend(mfcc)\n",
    "    atributos.extend(contrast)\n",
    "    atributos.extend(tonnetz)\n",
    "    atributos.extend(rhythm_features)\n",
    "    atributos.extend(flatness)\n",
    "    atributos.extend(bandwidth)\n",
    "    #atributos.extend(centroid)\n",
    "    #atributos.extend(flux)\n",
    "    #atributos.extend(harmonics)\n",
    "    #atributos.extend(mel_spectrogram)\n",
    "\n",
    "    atributos.extend(mp3s[i])\n",
    "    i += 1\n",
    "\n",
    "    dados.append(atributos)\n",
    "\n",
    "df = pd.DataFrame(dados)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivos.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\rolda\\OneDrive\\Documentos\\IaSom\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metodo</th>\n",
       "      <th>f1</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>std</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.604866</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>0.053801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.575832</td>\n",
       "      <td>0.581757</td>\n",
       "      <td>0.092856</td>\n",
       "      <td>0.444943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.572392</td>\n",
       "      <td>0.565986</td>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.199979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.552719</td>\n",
       "      <td>0.551904</td>\n",
       "      <td>0.099407</td>\n",
       "      <td>0.056998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.541034</td>\n",
       "      <td>0.535688</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>4.833311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.534993</td>\n",
       "      <td>0.583836</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.530731</td>\n",
       "      <td>0.631714</td>\n",
       "      <td>0.141416</td>\n",
       "      <td>0.056110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.526900</td>\n",
       "      <td>0.512395</td>\n",
       "      <td>0.122563</td>\n",
       "      <td>0.582957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           metodo        f1   AUC-ROC       std     tempo\n",
       "3            ExtraTreesClassifier  0.604866  0.547794  0.052849  0.053801\n",
       "6  HistGradientBoostingClassifier  0.575832  0.581757  0.092856  0.444943\n",
       "2          RandomForestClassifier  0.572392  0.565986  0.088736  0.199979\n",
       "0          DecisionTreeClassifier  0.552719  0.551904  0.099407  0.056998\n",
       "4      GradientBoostingClassifier  0.541034  0.535688  0.114100  4.833311\n",
       "1             ExtraTreeClassifier  0.534993  0.583836  0.111094  0.001000\n",
       "7              LogisticRegression  0.530731  0.631714  0.141416  0.056110\n",
       "5              AdaBoostClassifier  0.526900  0.512395  0.122563  0.582957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('arquivos.csv')\n",
    "\n",
    "X = df.drop(columns=['437']).drop(columns=['0']).values\n",
    "y = df['437'].values\n",
    "\n",
    "classificadores = [\n",
    "    DecisionTreeClassifier(random_state=42,max_depth=6),\n",
    "    ExtraTreeClassifier(random_state=42,max_depth=6),\n",
    "    RandomForestClassifier(random_state=42,max_depth=6),\n",
    "    ExtraTreesClassifier(random_state=42,max_depth=6),\n",
    "    GradientBoostingClassifier(random_state=42,max_depth=6),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    HistGradientBoostingClassifier(random_state=42,max_depth=6),\n",
    "    LogisticRegression(random_state=42),\n",
    "]\n",
    "\n",
    "resultados = []\n",
    "for cls in classificadores:\n",
    "    res = cross_validate(cls, X, y, cv=5, scoring='f1')\n",
    "    res1 = cross_validate(cls, X, y, cv=5, scoring='roc_auc')\n",
    "    resultados.append(\n",
    "        {'metodo': cls.__class__.__name__, \n",
    "         'f1': res['test_score'].mean(), \n",
    "         'AUC-ROC': res1['test_score'].mean(),\n",
    "         'std': res['test_score'].std(), \n",
    "         'tempo': res['fit_time'].mean(),\n",
    "         }\n",
    "    )\n",
    "\n",
    "df_res = pd.DataFrame(resultados)\n",
    "df_res.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([218, 272], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas = ExtraTreeClassifier(random_state=42,max_depth=5)\n",
    "clas.fit(X, y)\n",
    "\n",
    "Xr = df[df.columns[1:437]].values\n",
    "y_pred = clas.predict(Xr)\n",
    "df['Valido'] = y_pred\n",
    "#ds.reset_index(inplace=True)\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc770781a7a43598a606ab3dc885845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output(), Output(), Output(), Output()))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, Audio, display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "blocos = []\n",
    "for i, row in df.head(5).iterrows():\n",
    "    nome = row[\"0\"].split(\".\")[0]\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        display(Image(f'Charts/{nome}.png'))\n",
    "        display('Inválido' if row['Valido'] == 1 else 'Válido')\n",
    "        display(Audio(f'MP3/{row[\"0\"]}'))\n",
    "    blocos.append(out)\n",
    "widgets.HBox(blocos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
